{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing framework \"pipeline\"\n",
    "\n",
    "_Alex Malz (NYU)_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import string\n",
    "import itertools\n",
    "import random\n",
    "import numpy as np\n",
    "import sklearn as skl\n",
    "from sklearn import metrics\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import proclam\n",
    "from proclam import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. True classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the `proclam.Simulator` superclass and the simulator subclass you want to test.  In this notebook, I'm going to use an unbalanced distribution of true classes such that the probability of an object being in class $m$ (with $0 \\leq m \\leq M$) is proportional to $10^{y}$, where $y$ is a draw from a uniform distribution $U(0,M)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from proclam.simulators import simulator\n",
    "from proclam.simulators import logunbalanced"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create an instantiation of the simulator for the true dataset class distribution scheme.  If you use the base superclass instead of a subclass, the default scheme will be to assign all objects the same class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "A = proclam.simulators.logunbalanced.LogUnbalanced()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, simulate a truth catalog.  In this case, there are 3 true classes and 100 objects in the catalog.  The output will be a `numpy.ndarray` with 100 entries, each of which is the index of the class for that catalog member."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "A = proclam.simulators.logunbalanced.LogUnbalanced(seed=None)\n",
    "M_classes = 3\n",
    "N_objects = 1000\n",
    "names = [''.join(random.sample(string.ascii_lowercase, 2)) for i in range(M_classes)]\n",
    "truth = A.simulate(M_classes, N_objects)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check that the class distribution is as expected with a histogram of the true classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5,0,u'class')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZkAAAEKCAYAAADAVygjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nISNJaub/AeqE60tpdHIaAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10a3ee950>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d = np.diff(np.unique(truth)).min()\n",
    "left_of_first_bin = truth.min() - float(d)/2\n",
    "right_of_last_bin = truth.max() + float(d)/2\n",
    "plt.hist(truth, np.arange(left_of_first_bin, right_of_last_bin + d, d), log=True)\n",
    "plt.xticks(range(max(truth)+1), names)\n",
    "\n",
    "# plt.hist(truth, log=True)\n",
    "plt.ylabel('counts')\n",
    "plt.xlabel('class')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Mock classifications"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the `proclam.Classifier` superclass and the classifier subclass you want to test.  In this notebook, I'm going to use a very stupid classifier that takes a random guess."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from proclam.classifiers import classifier\n",
    "from proclam.classifiers import guess\n",
    "from proclam.classifiers import from_cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create an instantiation of the classifier of a particular scheme.  If you use the base superclass instead of a subclass, the default classification scheme will return the true classes.\n",
    "\n",
    "Then, \"classify\" the \"data.\"  By default, classification results will also include an extra column for \"other\" classes beyond the number in the training set, but in this example let's assume it knows of the M classes in the training set without leaving room for additional classes.  The output will be a `numpy.ndarray` with N rows and column entries representing each catalog member's posterior probability for being of each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "B = proclam.classifiers.guess.Guess(seed=None)\n",
    "predictionB = B.classify(3, truth, other=False)\n",
    "# print(prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's compare this to a smarter classifier based on a confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.83512513 0.04878879 0.13218275]\n",
      " [0.05794841 0.87021617 0.06402457]\n",
      " [0.08052661 0.08622724 0.82748843]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,u'true class')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAREAAAEMCAYAAADj3ILLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nUpP/A6C90VpwWhWdAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10a46ae90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm = np.eye(3) + 0.2 * np.random.uniform(size=(3, 3))\n",
    "cm /= np.sum(cm, axis=1)\n",
    "print(cm)\n",
    "plt.matshow(cm)#, vmin=0., vmax=1.)\n",
    "plt.xticks(range(max(truth)+1), names)\n",
    "plt.yticks(range(max(truth)+1), names)\n",
    "plt.xlabel('predicted class')\n",
    "plt.ylabel('true class')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to support classifiers with an extra class for classes not represented in the training set, but the infrastructure isn't there yet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.05072211 0.14210554 0.80717234]\n",
      " [0.0604898  0.52077337 0.41873683]\n",
      " [0.14210503 0.1558574  0.70203758]\n",
      " ...\n",
      " [0.15244809 0.2273644  0.62018751]\n",
      " [0.12322287 0.09166048 0.78511666]\n",
      " [0.30939597 0.05114783 0.6394562 ]]\n"
     ]
    }
   ],
   "source": [
    "C = proclam.classifiers.from_cm.FromCM(seed=None)\n",
    "predictionC = C.classify(cm, truth, other=False)\n",
    "print(predictionC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also try this with real data from `SNPhotCC`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((array([0, 1, 2]), array([243, 670,  87])), (array([0, 1, 2]), array([255, 603, 142])))\n",
      "[[ 59. 151.  33.]\n",
      " [172. 396. 102.]\n",
      " [ 24.  56.   7.]]\n",
      "[[0.23137255 0.25041459 0.23239437]\n",
      " [0.6745098  0.65671642 0.71830986]\n",
      " [0.09411765 0.09286899 0.04929577]]\n",
      "[[0.23137255 0.25041459 0.23239437]\n",
      " [0.6745098  0.65671642 0.71830986]\n",
      " [0.09411765 0.09286899 0.04929577]]\n"
     ]
    }
   ],
   "source": [
    "probs = np.loadtxt('examples/classifications/templates_knn.dat', usecols=[1, 2, 3], skiprows=1)\n",
    "# print(np.shape(probs))\n",
    "probs = probs[:N_objects]\n",
    "# print(np.shape(probs))\n",
    "\n",
    "truth_snphotcc = np.loadtxt('examples/key.txt', usecols=[1], skiprows=1)\n",
    "# print(np.shape(truth_snphotcc))\n",
    "truth_snphotcc -= 1.\n",
    "truth_snphotcc = truth_snphotcc.astype(int)[:N_objects]\n",
    "# print(np.shape(truth_snphotcc))\n",
    "\n",
    "CM = proclam.metrics.util.prob_to_cm(probs, truth_snphotcc, vb=True)\n",
    "print(CM)\n",
    "\n",
    "F = proclam.classifiers.from_cm.FromCM(seed=None)\n",
    "predictionF = F.classify(CM, truth_snphotcc, other=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Is this confusion matrix supposed to look so bad?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Metric values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the `proclam.Metric` superclass and the metric subclass you want to test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from proclam.metrics import metric\n",
    "from proclam.metrics import logloss\n",
    "from proclam.metrics import brier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Probabilistic metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try out the [logloss metric](https://en.wikipedia.org/wiki/Loss_functions_for_classification#Cross_entropy_loss).  The logloss metric is a sum over $LL_{ij} = -y_{ij}\\ln[p_{ij}]$ for predicted probabilities $p$ and true class indicators $y$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Averaging by per_item.\n",
      "proclam implementation of log-loss: 1.319865811630585\n",
      "Averaging by per_item.\n",
      "proclam implementation of log-loss: 0.4978165328350087\n",
      "Averaging by per_item.\n",
      "proclam implementation of log-loss: 1.2654933485445627\n"
     ]
    }
   ],
   "source": [
    "for candidate in [predictionB, predictionC]:\n",
    "    D = proclam.metrics.logloss.LogLoss()\n",
    "    performance = D.evaluate(candidate, truth, averaging='per_item')\n",
    "    print('proclam implementation of log-loss: '+str(performance))\n",
    "#     alternative = skl.metrics.log_loss(truth, candidate, normalize=True)\n",
    "#     print('scikit-learn implementation of log-loss: '+str(alternative))\n",
    "\n",
    "D = proclam.metrics.logloss.LogLoss()\n",
    "performance = D.evaluate(predictionF, truth_snphotcc, averaging='per_item')\n",
    "print('proclam implementation of log-loss: '+str(performance))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try the [Brier score](https://en.wikipedia.org/wiki/Brier_score#Original_definition_by_Brier) this time.  The multi-class Brier score is $BS = \\frac{1}{N}\\sum\\limits _{t=1}^{N}\\sum\\limits _{i=1}^{R}(f_{ti}-o_{ti})^2$ for $N$ objects, $R$ classes, predicted probabilities $f$, and $o_{i}$ of 1 for true class $i$ and 0 for other true classes.\n",
    "\n",
    "First we create an instantiation of the metric.  Then, we calculate the metric value.  For binary classes, we can compare to the implementation in `scikit-learn`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "proclam implementation of Brier score: 0.25402057572862935\n",
      "proclam implementation of Brier score: 0.08700109949180425\n",
      "proclam implementation of Brier score: 0.25201485848341987\n"
     ]
    }
   ],
   "source": [
    "for candidate in [predictionB, predictionC]:\n",
    "    E = proclam.metrics.brier.Brier()\n",
    "    performance = E.evaluate(candidate, truth)\n",
    "    print('proclam implementation of Brier score: '+str(performance))\n",
    "    \n",
    "    if M_classes == 2:\n",
    "        skl_truth = proclam.metrics.util.truth_reformatter(truth).T[0]\n",
    "        alternative = skl.metrics.brier_score_loss(skl_truth, prediction.T[0])\n",
    "        print('scikit-learn implementation: '+str(alternative))\n",
    "        \n",
    "E = proclam.metrics.brier.Brier()\n",
    "performance = E.evaluate(predictionF, truth_snphotcc)\n",
    "print('proclam implementation of Brier score: '+str(performance))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deterministic metrics\n",
    "\n",
    "Let's check that reducing the probabilities to class point estimates actually does what we want; the one based on a good confusion matrix should do better than the random guesser.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "true positives 0.33941139065855624\n",
      "false negatives0.6605886093414438\n",
      "true positives 0.8753194399452903\n",
      "false negatives0.12468056005470973\n",
      "true positives 0.2827198812162148\n",
      "false negatives0.7172801187837852\n"
     ]
    }
   ],
   "source": [
    "from proclam.metrics import util as pmu\n",
    "\n",
    "for candidate in [predictionB, predictionC]:\n",
    "    intermediate = pmu.prob_to_det(candidate)\n",
    "    rates = pmu.det_to_rate(intermediate, truth, vb=False)\n",
    "\n",
    "    print('true positives '+str(rates.TPR))\n",
    "    print('false negatives'+str(rates.FNR))\n",
    "    \n",
    "intermediate = pmu.prob_to_det(predictionF)\n",
    "rates = pmu.det_to_rate(intermediate, truth_snphotcc, vb=False)\n",
    "print('true positives '+str(rates.TPR))\n",
    "print('false negatives'+str(rates.FNR))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can test the familiar area under the receiver operating curve, the AUC of the ROC.  The ROC itself is defined as pairs of points $(TPR(t), FPR(t))$, where $t$ is the critical probability used for assignment of a class $m$; effectively, we make a binary confusion matrix by assigning a class $m$ to objects with $p(\\hat{x}=m | x=m) > t$.  The AUC is the area under the curve created by evaluating the ROC at many thresholds t.  Calling it might look like this: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.03289061656408604, 0.02582874419609113, 0.02162833387323182]\n"
     ]
    }
   ],
   "source": [
    "from proclam.metrics import roc_auc\n",
    "\n",
    "G = proclam.metrics.roc_auc.ROCAUC()\n",
    "performance = G.evaluate(predictionB, truth, thresholds=50)\n",
    "print(performance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Next steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once there are more simulators, classifiers, and metrics, we'll loop over tests and plot comparisons.  Stay tuned for more!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
